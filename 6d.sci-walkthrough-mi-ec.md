# SCI Walkthrough - Methodology & Implementation - Embodied Carbon

Let's revisit our depenancy tree to see what we did and what's remaining.

â˜‘ï¸ sci
- âœ… operational-carbon
  - âœ… operational-energy
    - âœ… cpu-energy
      - ðŸ cpu-utilization(80)
      - ðŸ cloud-vendor(Azure)
      - ðŸ cloud-instance-type(Standard_A2m_v2)
    - âœ… memory-energy
      - ðŸ memory-utilization(8)
  - âœ… carbon-intensity
    - ðŸ cloud-region(West UK)
- â˜‘ï¸ embodied-carbon
    - ðŸ cloud-vendor(Azure)
    - ðŸ cloud-instance-type(Standard_A2m_v2)
- â˜‘ï¸ functional-unit
  - ðŸ site-visits(550)

In this module we are going to work through the methodology for the embodied carbon impact dependancy.

## `embodied-carbon`

### Metholdology

Carbon is emitted when the hardware used to run an application is manufactured, and more will be emitted when the hardware is disposed of. This is the â€œembodiedâ€ or â€œembeddedâ€ carbon, represented by the symbol `M` in the `SCI` equation.

Calculating embodied emissions is perhaps the most **difficult** component to measure due to the lack of **open** data regarding the embodied emissions of hardware. They typically come from manufacturers conducting life cycle assessments for the products they sell and sharing the total embodied carbon in a data sheet. However, few manufacturers do this, and those that do tend to only do it for a subset of their products of those only a few publish the data for everyone to see. 

> [!IMPORTANT]
> If you work for a large enterprise organization you might be able to get access to this data from your suppliers. If they don't publish it openly, they do often release it to their suppliers under an NDA. We recomend reaching out to your sustainabilty department and seeing if you have access to embodied carbon values from your suppliers.

> [!IMPORTANT]
> If you have access to or can obtain better, more accurate data regarding the embodied carbon of your devices, we strongly recommend that you do so and **do not use** the above methodology. The methodology and underlying data sources are woefully incomplete since there is a deep lack of public disclosure here. If you work for a large organization, you might have the ability to request detailed embodied carbon values from your suppliers under a non-disclosure agreement. We strongly recommend you pursue that approach if you can and only use the above methodology as a fallback.

If you do not or cannot get access to this data, this means you often have to find analogs or models to estimate embodied carbon for hardware components.

A popular model for embodied carbon is the one published in https://medium.com/teads-engineering/building-an-aws-ec2-carbon-emissions-dataset-3f0fd76c98ac, which is also used by [Cloud Carbon Footprint.](https://www.cloudcarbonfootprint.org/docs/embodied-emissions) They define a minimal â€œbaselineâ€ rack server with a given embodied carbon value and then specify how much carbon to add to the baseline for each additional component your real server has.

**TODO - explain how the above works**

As you can imagine, the aove model is poor, outdated and may lead to very innacurate figures, however it's big advantage is that if you have some generic data regarding your servers then you can estimate the embodied emissions.

### Implementation

#### Server Meta-Data

The CCF model, in order to estimate the embodied carbon of your server, needs to know several bits of information such as the number of vCPUs, amount of memory, and how many SSD drives, etc.

As you can see the model we are goign to use needs some additional meta data about the server, including the total amount of memory, the number of vCPUs and the number of SSDs. The cloud instance dataset from the GSF already has some of this data so let's just adjust that plugin configuration to output some additional values.

The highlighed rows below are the lines we changed to output additional columns:

```yaml
cloud-instance-metadata:
  method: CSVLookup     
  path: 'builtin'
  config:
    filepath: /Users/jawache/Development/gsf/if-course/src/cloud-metdata-azure-instances.csv 
    query:              
      instance-class: "cloud-instance"
    # highlight-start          
    output: "*"
    # highlight-end        
```        

> [!IMPORTANT]
> The GSF cloud instance dataset dosn't at the time of writing have good data regarding the number of SSDs for each server. Community contributions are welcome!

#### Embodied Model

The Impact Framework `builtins` has a plugin, `SciEmbodied`, for simplifying the application of the above methodology. You simply specify your hardware in your input data, and it calculates the embodied carbon using the Cloud Carbon Footprint model.

The plugin initialization is extremely simpleâ€”you do not have to provide any config data at all unless you want to override some default settings. You can simply add the following to your `initialize: plugins:` block:

```yaml
embodied-carbon:
  path: builtin
  method: SciEmbodied
```

The plugin does expect the inputs to be named differently to how we have named them, Impact Framework has a feature specifically for this purpose called mappings, let's configure it like so:

```yaml
embodied-carbon:
  path: builtin
  method: SciEmbodied
```

***** TODO I'M HERE NEED MAPPING DOCS ***




You can add these values either to the defaults or inputs of a component like so:

```yaml
inputs:
  - vCPUs: 2
  - memory: 16
  - SSD: 1
```

This is all that is required for the `SciEmbodied` model to run. It will add the total embodied emissions for the server to the output data using the name `embodied-carbon`.

More details regarding the SciEmbodied model can be found [here](https://github.com/Green-Software-Foundation/if/blob/main/src/if-run/builtins/sci-embodied/README.md).



### Implementation

ADD RTC SO IT GIVES US CA

## `operational-carbon`

### Methodology

Now we have `carbon-intensity` and `operational-energy`, we simply need to multiply them together to create `operational-carbon`. 

### Implementation

We will use the Multiply plugin, and configure it to multiply `operational-energy` by `carbon-intensity` and output `operational-carbon` like so:

```yaml
calculate-operational-carbon:
  method: Multiply
  path: builtin
  config:
    input-parameters: 
      - operational-energy
      - carbon-intensity
    output-parameter: operational-carbon
```
## Full Manifest

The full manifest so far now looks like so:

```yaml
name: sci-walkthrough
description: This manifest file computes the carbon per visit for our website
tags:
initialize:
  plugins:
    memory-utilization-to-memory-energy:        
      method: Coefficient
      path: "builtin"
      config:
        input-parameter: memory-utilization 
        coefficient: 0.00039                
        output-parameter: memory-energy   
    cloud-instance-to-cpu-tdp:
      method: CSVLookup     
      path: 'builtin'
      config:
        filepath: /Users/jawache/Development/gsf/if-course/src/cloud-metdata-azure-instances.csv 
        query:              
          instance-class: "cloud-instance"
        output:             
          - cpu-tdp                  
    cpu-utilization-to-tdp-multiplier:
      method: Interpolation
      path: "builtin"
      config:
        method: linear
        x: [0, 10, 50, 100]
        y: [0.12, 0.32, 0.75, 1.02]
        input-parameter: "cpu-utilization"
        output-parameter: "tdp-multiplier"
    tdp-multiplier-to-cpu-power:
      method: Multiply
      path: builtin
      config:
        input-parameters: 
          - tdp-multiplier
          - cpu-tdp
        output-parameter: "cpu-power"
    cpu-power-to-cpu-energy:
      method: Divide
      path: "builtin"
      config:
        numerator: cpu-power
        denominator: 1000
        output: cpu-energy
    to-operational-energy:
      path: "builtin"
      method: Sum
      config:
        input-parameters:
          - memory-energy
          - cpu-energy
        output-parameter: operational-energy
    to-operational-carbon:
      method: Multiply
      path: builtin
      config:
        input-parameters: 
          - operational-energy
          - carbon-intensity
        output-parameter: operational-carbon        
tree:
  children:
    server-1:
      defaults:
        cloud-region: West UK    
        cloud-instance: Standard_A2m_v2
        cloud-provider: Azure     
        carbon-intensity: 120   
      pipeline:
        compute:
          - memory-utilization-to-memory-energy
          - cloud-instance-to-cpu-tdp
          - cpu-utilization-to-tdp-multiplier
          - tdp-multiplier-to-cpu-power
          - cpu-power-to-cpu-energy
          - to-operational-energy
          - to-operational-carbon
      inputs:
        - timestamp: 2023-08-01T00:00
          duration: 3600
          memory-utilization: 8.8
          cpu-utilization: 80
          site-visits: 210
```          

And now if we run in the terminal with 

```bash
if-run -m sci-walkthrough.yml
```

An output manifest is printed to the terminal with these `outputs` appended.

```yaml
outputs:
  - timestamp: 2023-08-01T00:00
    duration: 3600
    memory-utilization: 8.8
    cpu-utilization: 80
    site-visits: 210
    cloud-region: West UK
    cloud-instance: Standard_A2m_v2
    cloud-provider: Azure
    carbon-intensity: 120
    memory-energy: 0.003432
    cpu-tdp: 205
    tdp-multiplier: 0.912
    cpu-power: 186.96
    cpu-energy: 0.18696000000000002
    operational-energy: 0.190392
    # highlight-start    
    operational-carbon: 22.84704
    # highlight-end    
```

You can see that we now have a manifest that calcualtes `operational-carbon`, there is still more to do however until we can compute a sci score.