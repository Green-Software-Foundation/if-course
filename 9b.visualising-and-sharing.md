# Visualising and Sharing

In the previous module you planned an investigation — defining the boundary, components, and pipelines for each part of your application. This module covers the final phase: turning that plan into a running manifest, visualising the results, and sharing your work.

## Writing the Manifest

Writing the manifest is now a case of collating everything from your scoping and IDOMI work into YAML format.

Each time you use a plugin, for example `Sum`, it needs to be instantiated with a unique name and appropriate config. If you use `Sum` in both the networking component and the servers component, you need two instances in your `initialize: plugins` block, each with its own config and a descriptive name. For example:

```yaml
initialize:
  plugins:
    sum-networking-energy:
      path: "builtin"
      method: Sum
      config:
        input-parameters:
          - carbon-from-routers
          - carbon-from-switches
        output-parameter: carbon
    sum-server-energy:
      path: "builtin"
      method: Sum
      config:
        input-parameters:
          - carbon-from-cpu-util
          - carbon-from-mem-util
        output-parameter: carbon
```

Then build your tree, organising components according to the hierarchy you designed during scoping. Each component has the structure you're now familiar with:

```yaml
component-name:
  pipeline:
    compute:
      - plugin-instance-1
      - plugin-instance-2
  defaults:
    cloud-region: westeurope
  inputs:
    - timestamp: "2023-12-12T00:00:00.000Z"
      duration: 3600
      cpu-utilization: 20
```

Finally, add the `aggregation` config so metrics are summarised across your tree:

```yaml
aggregation:
  metrics:
    - carbon
    - sci
  type: "both"
```

## Running the Manifest

Execute your manifest by passing its path to `if-run`:

```bash
if-run -m manifest.yml
```

This will run your manifest and display the outputs to the console. You can also add `-o output-file.yml` to redirect the outputs to a file instead.

## Visualising Results

You can display your results using the Impact Framework [visualiser](https://viz.if.greensoftware.foundation). You'll need to pass a URL to your file. The simplest approach is to host your file on a service like Github and pass the URL of the raw file to the visualiser. Alternatively, you could serve the file locally.

The visualiser displays a donut chart with sections for each top-level component in the tree. You can click into any segment. If the clicked segment has child components, the donut chart will show the proportions accounted for by each child. If a clicked segment has no children, it will display a flyout with the granular information about that component.

If you prefer not to serve your own manifest you can use this prepared example:

https://viz.if.greensoftware.foundation/?url=https%3A%2F%2Fraw.githubusercontent.com%2FGreen-Software-Foundation%2Fif-db%2Frefs%2Fheads%2Fmain%2Fmanifests%2Fgsf-website%2Fgsf-website-output.yml

## Sharing and Verifying Manifests

An Impact Framework output file can be thought of as an executable audit. It includes your emissions and SCI estimates, but it also includes all the input data, configuration and model pipelines that were executed, so anyone can inspect your work.

Not only that, but your output file can be re-run through Impact Framework to check that the results were calculated correctly. Let's say you receive an output file from a peer and you want to check their working and suggest improvements. Step 1 is to verify that their reported results truly resulted from executing the stated models over the given input data.

The tool for this is `if-check`:

```bash
if-check -m outputs.yml
```

This re-executes the file and verifies that the given results match the re-executed ones.

Next, you can inspect the model pipelines — do you agree with the models that were executed? Do you agree with the coefficient values used? If not, swap them out, rerun the manifest and send it back to the authors. In this way, environmental impact reporting becomes a discussion, rather than a one-way transfer of information. If the manifest is made public, this process can be used to crowdsource consensus for your environmental impact measurements.

## Key Takeaways

- The Impact Framework visualiser helps you understand which parts of your system contribute most to emissions.
- Output files are executable audits — they contain everything needed to reproduce and verify your results.
- `if-check` re-executes an output file to verify that reported results match the stated methodology.
- Sharing manifests enables collaborative, discussion-based environmental impact reporting.
