# Working with Time Series Data

So far in our SCI walkthrough, the `inputs` array has only had a single observation — one hour of data for our server. In practice, you'll want to measure your application over many hours, days, or even months. This module covers how Impact Framework handles multiple observations over time.

## Multiple Observations in Inputs

When your `inputs` array contains more than one observation, Impact Framework passes **each observation independently through the entire plugin pipeline**. Every entry is treated identically and atomically — the same set of plugins runs on each one, producing the same set of output parameters.

This means extending our SCI walkthrough to cover multiple time periods is straightforward: we simply add more entries to `inputs`, each with its own `timestamp`, `duration`, and varying observation values.

### Extending Our Walkthrough

Let's say we gathered data from our monitoring dashboard for three consecutive days. CPU utilisation, memory utilisation, and site visits all varied across the period:

```yaml
inputs:
  - timestamp: 2023-08-01T00:00
    duration: 3600
    memory-utilization: 8.8
    cpu-utilization: 80
    site-visits: 210
  - timestamp: 2023-08-02T00:00
    duration: 3600
    memory-utilization: 5.2
    cpu-utilization: 55
    site-visits: 190
  - timestamp: 2023-08-03T00:00
    duration: 3600
    memory-utilization: 15.4
    cpu-utilization: 90
    site-visits: 340
```

Nothing else in the manifest needs to change — the same plugins, pipeline, and defaults all apply. Impact Framework will run each of the three observations through our full SCI pipeline independently.

### Running It

Using the same manifest from module 10 with the updated `inputs` above, we run:

```bash
if-run -m sci-walkthrough.yml
```

The output now contains three entries, one for each timestep:

```yaml
outputs:
  - timestamp: 2023-08-01T00:00
    duration: 3600
    cpu-utilization: 80
    memory-utilization: 8.8
    site-visits: 210
    # ... intermediate values omitted for clarity ...
    operational-carbon: 53.913302640000005
    embodied-carbon: 32.81963470319634
    carbon: 86.73293734319634
    # highlight-start
    sci: 0.413013987348554
    # highlight-end
  - timestamp: 2023-08-02T00:00
    duration: 3600
    cpu-utilization: 55
    memory-utilization: 5.2
    site-visits: 190
    # ...
    operational-carbon: 45.67900221000001
    embodied-carbon: 32.81963470319634
    carbon: 78.49863691319635
    # highlight-start
    sci: 0.41315072059577024
    # highlight-end
  - timestamp: 2023-08-03T00:00
    duration: 3600
    cpu-utilization: 90
    memory-utilization: 15.4
    site-visits: 340
    # ...
    operational-carbon: 57.77687412000001
    embodied-carbon: 32.81963470319634
    carbon: 90.59650882319636
    # highlight-start
    sci: 0.26646032006822457
    # highlight-end
```

Notice how the SCI score varies across the three days:

| Day | CPU | Visits | SCI (gCO2e/visit) |
|-----|-----|--------|--------------------|
| Aug 1 | 80% | 210 | 0.41 |
| Aug 2 | 55% | 190 | 0.41 |
| Aug 3 | 90% | 340 | 0.27 |

Day 3 had the highest CPU utilisation (and therefore the highest total carbon), but it also had the most visits. Because SCI is carbon **per visit**, day 3 actually had the best score — the carbon cost was spread across more users.

This is exactly why the SCI uses a functional unit rather than total carbon: it surfaces efficiency rather than just raw emissions. A busy day isn't necessarily a bad day.

> [!NOTE]
> The `embodied-carbon` value is the same for all three observations. This is expected — embodied carbon depends on the hardware specification and the duration of use, not on how hard the CPU is working. Since all three observations have the same 1-hour duration and the same server, the embodied carbon is identical.

In the next module we'll look at what happens when you have **multiple components** whose time series don't line up, and how Impact Framework's `time-sync` feature can handle that.
