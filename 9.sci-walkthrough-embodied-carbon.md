# SCI Walkthrough - Methodology & Implementation - Embodied Carbon

Let's revisit our dependency tree to see what we did and what's remaining.

â˜‘ï¸ sci
- âœ… operational-carbon
  - âœ… operational-energy
    - âœ… cpu-energy
      - ðŸ cpu-utilization(80)
      - ðŸ cloud-vendor(Microsoft Azure)
      - ðŸ cloud-instance-type(Standard_A2m_v2)
    - âœ… memory-energy
      - ðŸ memory-utilization(8)
  - âœ… carbon-intensity
    - ðŸ cloud-region(westeurope)
- â˜‘ï¸ embodied-carbon
    - ðŸ cloud-vendor(Microsoft Azure)
    - ðŸ cloud-instance-type(Standard_A2m_v2)
- â˜‘ï¸ functional-unit
  - ðŸ site-visits(550)

In this module we are going to work through the methodology for the embodied carbon impact dependency.

## `embodied-carbon`

### Methodology

Carbon is emitted when the hardware used to run an application is manufactured, and more will be emitted when the hardware is disposed of. This is the â€œembodiedâ€ or â€œembeddedâ€ carbon, represented by the symbol `M` in the `SCI` equation.

Calculating embodied emissions is perhaps the most **difficult** component to measure due to the lack of **open** data regarding the embodied emissions of hardware. They typically come from manufacturers conducting life cycle assessments for the products they sell and sharing the total embodied carbon in a data sheet. However, few manufacturers do this, and those that do tend to only do it for a subset of their products of those only a few publish the data for everyone to see. 

> [!IMPORTANT]
> If you work for a large enterprise organization you might be able to get access to this data from your suppliers. If they don't publish it openly, they do often release it to their suppliers under an NDA. We recommend reaching out to your sustainability department and seeing if you have access to embodied carbon values from your suppliers.

> [!IMPORTANT]
> If you have access to or can obtain better, more accurate data regarding the embodied carbon of your devices, we strongly recommend that you do so and **do not use** the above methodology. The methodology and underlying data sources are woefully incomplete since there is a deep lack of public disclosure here. If you work for a large organization, you might have the ability to request detailed embodied carbon values from your suppliers under a non-disclosure agreement. We strongly recommend you pursue that approach if you can and only use the above methodology as a fallback.

If you do not or cannot get access to this data, this means you often have to find analogs or models to estimate embodied carbon for hardware components.

A popular model for embodied carbon is the one published in https://medium.com/teads-engineering/building-an-aws-ec2-carbon-emissions-dataset-3f0fd76c98ac, which is also used by [Cloud Carbon Footprint.](https://www.cloudcarbonfootprint.org/docs/embodied-emissions) They define a minimal "baseline" rack server with a given embodied carbon value and then specify how much carbon to add to the baseline for each additional component your real server has.

**How this model works:** The baseline model starts with a minimal server configuration (typically 1 CPU, minimal memory, no storage) with a known embodied carbon value. For your actual server, you calculate the embodied carbon by taking this baseline value and adding incremental amounts for each additional component:
- Additional CPUs add X kg CO2e
- Each GB of memory adds Y kg CO2e
- Each SSD adds Z kg CO2e

The `SciEmbodied` plugin in Impact Framework implements this methodology, using coefficients derived from the Cloud Carbon Footprint model to automatically calculate embodied carbon based on your server specifications.

As you can imagine, the above model is poor, outdated and may lead to very inaccurate figures, however its big advantage is that if you have some generic data regarding your servers then you can estimate the embodied emissions.

### Implementation

#### Server Meta-Data

The CCF model needs to know several bits of information about your server such as the number of vCPUs, amount of memory, and how many SSD drives, etc.

In the previous module we used the GSF cloud instance dataset to look up `cpu-tdp` for our instance. That same dataset also contains `cpu-cores-utilized` and `memory-available` columns which we can use here. We just need to update our CSVLookup to output these additional columns and rename them to match what `SciEmbodied` expects.

Using the tuple syntax we learned in the previous module, we can select the specific columns we need and rename them in one step:

```yaml
cloud-instance-metadata:
  method: CSVLookup                    # <1>
  path: 'builtin'
  config:
    filepath: https://raw.githubusercontent.com/Green-Software-Foundation/if-course/refs/heads/main/src/cloud-metdata-azure-instances.csv
    query:
      instance-class: "cloud-instance"
    output:                            # <2>
      - ['cpu-tdp', 'cpu-tdp']
      - ['cpu-cores-utilized', 'vCPUs']
      - ['memory-available', 'memory']
```

- <1>: This is the same `CSVLookup` plugin we used before for CPU TDP, but now renamed from `cloud-instance-to-cpu-tdp` to `cloud-instance-metadata` since it outputs more than just the TDP.
- <2>: We use tuples to select three specific columns and rename them as needed. The `SciEmbodied` plugin expects parameters named `vCPUs` and `memory`, so we rename `cpu-cores-utilized` and `memory-available` to match. Note that when using tuples, all entries must use the tuple format â€” you can't mix plain strings and tuples.

> [!IMPORTANT]
> The GSF cloud instance dataset doesn't have data for SSD, HDD, or GPU counts. You'll need to research these yourself for each instance type you're modelling.

#### Embodied Model

The Impact Framework `builtins` has a plugin, `SciEmbodied`, for simplifying the application of the above methodology. It expects the following input parameters:

- `vCPUs` â€” number of virtual CPUs
- `memory` â€” amount of RAM in GB
- `ssd` â€” number of SSD drives
- `hdd` â€” number of HDD drives
- `gpu` â€” number of GPUs
- `duration` â€” how long the hardware was in use (we already have this in our inputs)

The plugin initialization is simple â€” you don't need to provide any config:

```yaml
embodied-carbon:
  path: builtin
  method: SciEmbodied
```

The `cloud-instance-metadata` CSVLookup gives us `vCPUs` and `memory`. For the remaining parameters (`ssd`, `hdd`, `gpu`) which aren't in the CSV, we add them as defaults based on our research of the instance specs.

> [!TIP]
> For the `Standard_A2m_v2` instance, the [Azure Av2-series VM size documentation](https://learn.microsoft.com/en-us/azure/virtual-machines/sizes/general-purpose/av2-series) shows it has 20 GiB of local temporary storage backed by a single SSD, no HDD, and no GPU. Sites like [Vantage](https://instances.vantage.sh/) are also useful for quickly comparing instance specs across cloud providers.

```yaml
defaults:
  ssd: 1
  hdd: 0
  gpu: 0
```

With this configuration, the `SciEmbodied` plugin will calculate the total embodied emissions for the server and output the result as `embodied-carbon` in gCO2e.

More details regarding the SciEmbodied model can be found [here](https://github.com/Green-Software-Foundation/if/blob/main/src/if-run/builtins/sci-embodied/README.md).

## Full Manifest

The full manifest now includes everything from the previous module plus the updated `cloud-instance-metadata` and new `embodied-carbon` plugins:

```yaml
name: sci-walkthrough
description: This manifest file computes the carbon per visit for our website
tags:
initialize:
  plugins:
    memory-utilization-to-memory-energy:
      method: Coefficient
      path: "builtin"
      config:
        input-parameter: memory-utilization
        coefficient: 0.00039
        output-parameter: memory-energy
    # highlight-start
    cloud-instance-metadata:
      method: CSVLookup
      path: 'builtin'
      config:
        filepath: https://raw.githubusercontent.com/Green-Software-Foundation/if-course/refs/heads/main/src/cloud-metdata-azure-instances.csv
        query:
          instance-class: "cloud-instance"
        output:
          - ['cpu-tdp', 'cpu-tdp']
          - ['cpu-cores-utilized', 'vCPUs']
          - ['memory-available', 'memory']
    # highlight-end
    cpu-utilization-to-tdp-multiplier:
      method: Interpolation
      path: "builtin"
      config:
        method: linear
        x: [0, 10, 50, 100]
        y: [0.12, 0.32, 0.75, 1.02]
        input-parameter: "cpu-utilization"
        output-parameter: "tdp-multiplier"
    tdp-multiplier-to-cpu-power:
      method: Multiply
      path: builtin
      config:
        input-parameters:
          - tdp-multiplier
          - cpu-tdp
        output-parameter: "cpu-power"
    cpu-power-to-cpu-energy:
      method: Divide
      path: "builtin"
      config:
        numerator: cpu-power
        denominator: 1000
        output: cpu-energy
    to-operational-energy:
      path: "builtin"
      method: Sum
      config:
        input-parameters:
          - memory-energy
          - cpu-energy
        output-parameter: operational-energy
    carbon-intensity-from-region:
      method: CSVLookup
      path: builtin
      config:
        filepath: https://raw.githubusercontent.com/Green-Software-Foundation/real-time-cloud/refs/heads/main/Cloud_Region_Metadata.csv
        query:
          cloud-provider: "cloud-provider"
          cloud-region: "cloud-region"
        output:
          - ['grid-carbon-intensity-average-consumption-annual', 'carbon-intensity']
    to-operational-carbon:
      method: Multiply
      path: builtin
      config:
        input-parameters:
          - operational-energy
          - carbon-intensity
        output-parameter: operational-carbon
    # highlight-start
    embodied-carbon:
      path: builtin
      method: SciEmbodied
    # highlight-end
tree:
  children:
    server-1:
      defaults:
        cloud-region: westeurope
        cloud-instance: Standard_A2m_v2
        cloud-provider: "Microsoft Azure"
        # highlight-start
        ssd: 1
        hdd: 0
        gpu: 0
        # highlight-end
      pipeline:
        compute:
          - memory-utilization-to-memory-energy
          # highlight-start
          - cloud-instance-metadata
          # highlight-end
          - cpu-utilization-to-tdp-multiplier
          - tdp-multiplier-to-cpu-power
          - cpu-power-to-cpu-energy
          - to-operational-energy
          - carbon-intensity-from-region
          - to-operational-carbon
          # highlight-start
          - embodied-carbon
          # highlight-end
      inputs:
        - timestamp: 2023-08-01T00:00
          duration: 3600
          memory-utilization: 8.8
          cpu-utilization: 80
          site-visits: 210
```

And now if we run in the terminal with

```bash
if-run -m sci-walkthrough.yml
```

An output manifest is printed to the terminal with these `outputs` appended.

```yaml
outputs:
  - timestamp: 2023-08-01T00:00
    duration: 3600
    memory-utilization: 8.8
    cpu-utilization: 80
    site-visits: 210
    cloud-region: westeurope
    cloud-instance: Standard_A2m_v2
    cloud-provider: Microsoft Azure
    ssd: 1
    hdd: 0
    gpu: 0
    memory-energy: 0.003432
    cpu-tdp: 205
    vCPUs: 2
    memory: 16
    tdp-multiplier: 0.912
    cpu-power: 186.96
    cpu-energy: 0.18696000000000002
    operational-energy: 0.190392
    carbon-intensity: 283.17
    operational-carbon: 53.913302640000005
    # highlight-start
    embodied-carbon: 32.81963470319634
    # highlight-end
```

You can see that we now have both `operational-carbon` and `embodied-carbon` calculated. We're getting close to a full SCI score â€” all that remains is to combine these and divide by the functional unit.
