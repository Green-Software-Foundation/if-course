# SCI Walkthrough

So far we have focussed on computing the impact `carbon`. In the previous module we learned about the `SCI` specification, in terms of Impact Framework `SCI` is an impact. 

In this module we will continue with our worked example but transform the impact from `carbon` to `sci`.

##Â IDOMI

As should be fairly standard now, our process starts with **IDOM**.

1. **Impacts**: What impact(s) do you want to compute?
2. **Dependencies**: Start building up an impact dependency tree.
3. **Observations**: What observation(s) can you gather that *could* be induced to an impact?
4. **Methodology**: What methodology will you select for inducing the observation(s), into the impact(s)?


## Impacts

In this specific case this server is serving a website and the `SCI` score we want to calculate is `Carbon per Visit`.

As a reminder, the SCI score is calculated as follows:

```mathematica
SCI = (E * I + M) / R
```

- `E` is operational energy
- `I` is carbon intensity
- `M` is embodied carbon
- `R` is the functional unit, in this case `site-visits`

Read more at the [SCI Guidance project](https://sci-guide.greensoftware.foundation/)

In the SCI specification `(E * I)` is often expressed as simply `O`, operational carbon, like so:

```mathematica
SCI = (O + M) / R
```

- `O` is operational carbon
- `M` is embodied carbon
- `R` is the functional unit.

So the impact property we want to compute is simply `sci` but in order to compute that we also need to gather observations which help us to compute `operational-energy`, `operational-embodied` and `carbon-intensity` and we will also need to source some observations so we can compute the function unit of **visits**.

### Boilerplate

Let's start with creating the boilerplate manifest file we will continue to flesh out.

```yaml
name: sci-walkthrough
description: This manifest file computes the carbon per visit for our website
initialize:
  plugins:
tree:
  children:
    server-1:
      defaults:
      pipeline:
      inputs:
```

## Dependency Tree

Let's start building up our dependency tree which help us determine the **right** methodology to calculate our impacts.

â˜‘ï¸ sci
- â˜‘ï¸ operational-carbon
  - â˜‘ï¸ operational-energy
  - â˜‘ï¸ carbon-intensity
- â˜‘ï¸ embodied-carbon
- â˜‘ï¸ functional-unit

Next up, let's explore the observations we can gather as well as if there is a common methodology to turn them into the impacts we need.

## Dependency, Observation, Methodology

### Functional Unit

In order to compute an SCI score of carbon per visit, we need to first compute the total carbon and then divide by the number of visits. 

This example is fairly straightforward since our website uses Google Analytics, and looking at the dashboard we can see that there is a field called visits, and on the day of question the visits was `550`.

Let's add this to our dependency tree like so:

sci
- operational-carbon
  - operational-energy
  - carbon-intensity
- embodied-carbon
- âœ… functional-unit
  - **ğŸ site-visits(550)**

And let's also add the first observation to our component:

```yaml
server-1:
    defaults:
    pipeline:
    inputs:
    - timestamp: 2023-08-06T00:00
      duration: 3600      
      # highlight-next-line
      site-visits: 550
```

###Â Operational Energy

From the SCI equation it's clear we need to calculate operational energy, the `E` in the equation.

For our server we want to figure out both the energy from the cpu and from the memory and sum them both up to get the operational energy.

sci
- operational-carbon
  - operational-energy
    - **cpu-energy**
    - **memory-energy**
  - carbon-intensity
- embodied-carbon
- functional-unit
  - site-visits(550)

In the previous modules we assumed the dashboard of our cloud provider gave us energy directly, but this unfortunatey is very unlikely so instead we need to look for a proxy metric that we can induce *into* energy.

For cpu energy, regardless the hosting provider most people will be able to get detailed data regarding the CPU utilizatiopn and there is a common methodology for estimating energy from cpu utilization using something called the thermal-design-power (tdp) of the CPU, we don't have details regarding the CPU, all we do have is the instance-type of the server so let's add that and see later how we can get the tdp for the instance-type

Let's add these dependencies to tree like so:

- operational-carbon
  - operational-energy
    - cpu-energy
      - ğŸ cpu-utilization(80)
      - ğŸ cloud-vendor(Azure)
      - ğŸ cloud-instance-type(Standard_A2m_v2)
    - memory-energy
  - carbon-intensity
- embodied-carbon
- functional-unit
  - site-visits(550)


As well as the CPU we also want to measure the energy consumption from memory, so similar to the previous module we will also gather **memory utilization** from our hosting providers monitoring dashboard.

Let's add that to the dependency tree:

â˜‘ï¸ sci
- â˜‘ï¸ operational-carbon
  - âœ… operational-energy
    - âœ… cpu-energy
      - ğŸ cpu-utilization(80)
      - ğŸ cloud-vendor(Azure)
      - ğŸ cloud-instance-type(Standard_A2m_v2)
    - âœ… memory-energy
      - **ğŸ memory-utilization(8)**
  - â˜‘ï¸ carbon-intensity
- â˜‘ï¸ embodied-carbon
- âœ… functional-unit
  - ğŸ site-visits(550)

So all together all the observations we can gather about our software is:

```yaml
server-1:
    defaults:
      # highlight-start
      cloud-instance: "Standard_A2m_v2"
      cloud-provider: Azure      
      # highlight-end    
    pipeline:
    inputs:
    - timestamp: 2023-08-06T00:00
      duration: 3600      
      site-visits: 550
      # highlight-start
      cpu-utilization: 80
      memory-utilization: 8      
      # highlight-end
```

> [!NOTE]
> Since `cloud-instance` and `cloud-provider` are the same for all inputs in this component, we add to the `defaults` section.

## Carbon Intensity

In previous modules since we were using an average value we manually looked it up and hardcoded using using a `Coeefficient` plugin. A better methodology would be to treat it as an observation since it could change over time and region for different components of your software system.

One useful observation we can gather for our server is that it's based in the **West UK** region in **Azure**. 

There is also a data set from the Real Time Carbon project in the GSF which surfaces average yearly values for carbon intensnty by cloud provider and region which we can use as the methodology.

> [!TIP]
> The recommended approach is to use a plugin such as the [WattTime plugin](https://github.com/WattTime/gsf-if-plugin) which if added to the pipeline uses the WattTime API to source the right carbon intensity values from their database for a given region and time.

Let's add this to our dependency tree, note that now we have carbon intensity we should be able to also compute the operational carbon.

â˜‘ï¸ sci
- **âœ… operational-carbon**
  - âœ… operational-energy
    - âœ… cpu-energy
      - ğŸ cpu-utilization(80)
      - ğŸ cloud-vendor(Azure)
      - ğŸ cloud-instance-type(Standard_A2m_v2)
    - âœ… memory-energy
      - ğŸ memory-utilization(8)
  - **âœ… carbon-intensity**
    - **ğŸ cloud-region(West UK)**
- â˜‘ï¸ embodied-carbon
- âœ… functional-unit
  - ğŸ site-visits(550)

Let's add this to our observation, since we don't expect the region of our server to change across time we will simply add this to the `defaults` whcih are automatically copied to the inputs for every timestep, like so:

```yaml
server-1:
    defaults:
      cloud-instance: "Standard_A2m_v2"
      cloud-provider: Azure      
      # highlight-start
      cloud-region: West UK      
      # highlight-end    
    pipeline:
    inputs:
    - timestamp: 2023-08-06T00:00
      duration: 3600      
      site-visits: 550
      cpu-utilization: 80
      memory-utilization: 8      
```

### Embodied Carbon

Embodied carbon is an impact that is often far harder to source from your hosting provider than energy, so this will likely be the hardest data to source and most likely will have to be modeled and estimated. 

Since the embodied carbon is associated with the hardware the software is running on, we need some observations which give us details regarding the hardware.

For this case we know the server is running on the Microsoft **Azure** cloud platform and the server instance we are specifically using is called **Standard_A2m_v2** in the Azure ecosystem.

Let's add these to the dependency tree, like so:

âœ… sci
- âœ… operational-carbon
  - âœ… operational-energy
    - âœ… cpu-energy
      - ğŸ cpu-utilization(80)
      - ğŸ cloud-vendor(Azure)
      - ğŸ cloud-instance-type(Standard_A2m_v2)
    - âœ… memory-energy
      - ğŸ memory-utilization(8)
  - âœ… carbon-intensity
    - ğŸ cloud-region(West UK)
- âœ… embodied-carbon
    - ğŸ cloud-vendor(Azure)
    - ğŸ cloud-instance-type(Standard_A2m_v2)
- âœ… functional-unit
  - ğŸ site-visits(550)

Now we have embodied carbon we have all the dependencies needed to compute the SCI so we tick them all off with âœ….

Our full manifest file now looks like so:

```yaml
name: sci-walkthrough
description: This manifest file computes the carbon per visit for our website
initialize:
  plugins:
tree:
  children:
    server-1:
        defaults:
          cloud-instance: "Standard_A2m_v2"
          cloud-provider: Azure      
          cloud-region: West UK      
        pipeline:
        inputs:
          - timestamp: 2023-08-06T00:00
            duration: 3600      
            site-visits: 550
            cpu-utilization: 80
            memory-utilization: 8    
```

Next up let's explore the methodologies we can use and how to implement them in the manifest file.